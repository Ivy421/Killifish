{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec13a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, re, csv,glob\n",
    "# target folder name\n",
    "sub_folder = ['d48','d77']\n",
    "sheetname = ['averaged_before_led_df','dist_vel_acc_df']\n",
    "RawExtract = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete previous folder, and create new blank folder to save extraction result\n",
    "if os.path.exists(os.getcwd()+'/Raw_Extraction'):\n",
    "    shutil.rmtree(os.getcwd()+'/Raw_Extraction')\n",
    "os.makedirs(os.getcwd()+'/Raw_Extraction', mode = 0o777, exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bcb21",
   "metadata": {},
   "source": [
    "# STEP 1. raw data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ee40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. output of avg_before.xlsx\n",
    "avg_bf_df = pd.DataFrame()\n",
    "for fish_life in sub_folder:\n",
    "    avg_before_path = os.getcwd()+ \"/\" + fish_life + \"/dabest_plots/paired/averaged_before_led_df.csv\"\n",
    "    avg_bf_df = pd.read_csv(avg_before_path)\n",
    "    avg_bf_df.to_csv(os.getcwd()+'/Raw_Extraction/%s_averaged_before_led.csv'%fish_life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8bddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpocessing fish group:d48\n",
      "rpocessing fish group:d77\n"
     ]
    }
   ],
   "source": [
    "# 2. output of during_LED\n",
    "\n",
    "# glob searching file name，例如 \"*.txt\" 或 \"file_*.jpg\"\n",
    "file_pattern = \"LED*\"\n",
    "during_led_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for fish_life in sub_folder:\n",
    "    print('rpocessing fish group:%s'%fish_life)\n",
    "    during_sep_file = glob.glob(os.getcwd() + \"/\"+ fish_life + \"/\"+ file_pattern)\n",
    "    #during_sep_file.append(os.getcwd()+ \"/\"+ fish_life + \"/start_y_trajectory_ymag_yup\")\n",
    "    #during_sep_file.append(os.getcwd()+ \"/\"+ fish_life + \"/trajectory_direction\")\n",
    "    loop=0\n",
    "    for subf in during_sep_file:\n",
    "        file_list = os.listdir(subf)\n",
    "        #print(subf)\n",
    "        \n",
    "        for filename in file_list:\n",
    "            if filename.endswith('.csv'):\n",
    "                #print(filename)\n",
    "                loop+=1\n",
    "                csv_content = pd.read_csv(subf +\"/\"+filename)\n",
    "                if loop == 1:\n",
    "                    during_led_df = pd.concat( [during_led_df,csv_content], axis = 1)\n",
    "                else:\n",
    "                    column_idx = csv_content.columns.get_loc(\"uroa_control\")\n",
    "                    useful_content = csv_content.iloc[:, column_idx+1:]\n",
    "                    during_led_df = pd.concat( [during_led_df,useful_content], axis = 1)\n",
    "    \n",
    "    \n",
    "    # firstly sort by name, secondly sort by day\n",
    "    during_led_df = during_led_df.sort_values(by= 'name')\n",
    "    during_led_df = during_led_df.groupby('name').apply(lambda x: x.sort_values(by='day')).reset_index(drop=True)\n",
    "    during_led_df.to_csv(os.getcwd()+'/Raw_Extraction/%s_during_led.csv'%fish_life,index = False)\n",
    "    during_led_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e917bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "during column name:['dist', 'vel', 'acc', 'head_angle', 'y_mag', 'trajectory_angle', 'start_y_from_led', 'trajectory_angle.1', 'y_up']\n",
      "during column name:['dist', 'vel', 'acc', 'head_angle', 'y_mag', 'trajectory_angle', 'start_y_from_led', 'trajectory_angle.1', 'y_up']\n"
     ]
    }
   ],
   "source": [
    "#3. output of diff by before to after\n",
    "\n",
    "diff_df = pd.DataFrame()\n",
    "for fish_life in sub_folder:\n",
    "    during_led_total = pd.read_csv(os.getcwd()+'/Raw_Extraction/%s_during_led.csv'%fish_life)\n",
    "    before_led_total = pd.read_csv(os.getcwd()+'/Raw_Extraction/%s_averaged_before_led.csv'%fish_life)\n",
    "    diff_df = during_led_total.iloc[:,:3]\n",
    "    dur_col_name =  during_led_total.columns[3:].tolist() #list\n",
    "    print('during column name:%s'%dur_col_name)\n",
    "    for colname in dur_col_name:\n",
    "        if colname in before_led_total.columns:\n",
    "            #print(colname)\n",
    "            #during_col_data = during_led_total[name]\n",
    "            #before_col_data = before_led_total[name]\n",
    "            diff_col_data = during_led_total[colname] - before_led_total[colname]\n",
    "            diff_df = pd.concat([diff_df,diff_col_data],axis = 1)\n",
    "    diff_df.to_csv(os.getcwd()+'/Raw_Extraction/%s_diff_led.csv'%fish_life,index = False)\n",
    "    dur_col_name = []\n",
    "    diff_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68906d27",
   "metadata": {},
   "source": [
    "# STEP 2 calculation of z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9404a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_score calculation from:E:\\RA\\KILLIFISH/Raw_Extraction\\d48_diff_led.csv\n",
      "59.496719061348266 257.06641849349097\n",
      "0.6327157509737876 2.8358457849114607\n",
      "18.981471501205846 85.07536902275015\n",
      "-26.961693934587323 77.8576765054616\n",
      "38.7768654441461 81.81440957283627\n",
      "-10.879703101404901 96.84505227659187\n",
      "-2.5052251680768975 62.1774007021324\n",
      "12.808449998489072 39.03195779916418\n",
      "Z_score calculation from:E:\\RA\\KILLIFISH/Raw_Extraction\\d77_diff_led.csv\n",
      "71.64177437138189 222.03986692984202\n",
      "0.7697075488677766 2.454105895501354\n",
      "23.091225316678045 73.6231732794538\n",
      "-47.31164484518505 94.49126476413662\n",
      "49.537210914747796 73.88559193121638\n",
      "-19.055673937100075 79.05207576402509\n",
      "1.2932728044294994 64.21831803426748\n",
      "18.487639161984525 36.5311716753007\n"
     ]
    }
   ],
   "source": [
    "# glob searching file name，例如 \"*.txt\" 或 \"file_*.jpg\"\n",
    "file_pattern = \"*diff*\"\n",
    "diff_led = pd.DataFrame()\n",
    "z_score = pd.DataFrame()\n",
    "diff_file_path = glob.glob(os.getcwd() + \"/Raw_Extraction/\"+file_pattern)\n",
    "for i in range(len(diff_file_path)):\n",
    "    \n",
    "    print('Z_score calculation from:%s'%diff_file_path[i])\n",
    "    diff_file = pd.read_csv(diff_file_path[i])\n",
    "    z_score = diff_file.iloc[:,:3]\n",
    "    colname = diff_file.columns\n",
    "    #print(colname)\n",
    "    for j in range (diff_file.shape[1] - 3):\n",
    "        data = diff_file.iloc[:, j+3]\n",
    "        average = data.mean()\n",
    "        std_deviation = data.std()\n",
    "        print(average,std_deviation)\n",
    "        z_score['z_%s'%colname[j+3]] = (diff_file.iloc[:,j+3]-average)/std_deviation\n",
    "    z_score.to_csv(os.getcwd()+'/Raw_Extraction/%s_z_score.csv'%sub_folder[i],index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be443e",
   "metadata": {},
   "source": [
    "# STEP 3 calculation of z diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14640cb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\RA\\KILLIFISH/Raw_Extraction\\d48_z_score.csv\n",
      "D1D3 D1D4:\n",
      " 20    1\n",
      "21    3\n",
      "22    4\n",
      "Name: day, dtype: int64\n",
      "D1D2,D1D4,D2D4:\n",
      " 147    1\n",
      "148    2\n",
      "149    4\n",
      "Name: day, dtype: int64\n",
      "day1 and 2:\n",
      " 222    1\n",
      "223    2\n",
      "Name: day, dtype: int64\n",
      "E:\\RA\\KILLIFISH/Raw_Extraction\\d77_z_score.csv\n",
      "D1D2,D1D3,D2D3:\n",
      " 40    1\n",
      "41    2\n",
      "42    3\n",
      "Name: day, dtype: int64\n",
      "D2D3,D2D4:\n",
      " 51    2\n",
      "52    3\n",
      "53    4\n",
      "Name: day, dtype: int64\n",
      "D2D3,D2D4:\n",
      " 126    2\n",
      "127    3\n",
      "128    4\n",
      "Name: day, dtype: int64\n",
      "D1D3 D1D4:\n",
      " 177    1\n",
      "178    3\n",
      "179    4\n",
      "Name: day, dtype: int64\n",
      "D1D2,D1D4,D2D4:\n",
      " 204    1\n",
      "205    2\n",
      "206    4\n",
      "Name: day, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "file_pattern = \"*z_score*\"\n",
    "z_score_ori = pd.DataFrame()\n",
    "df_move_col = pd.DataFrame()\n",
    "zscore_file_path = glob.glob(os.getcwd() + \"/Raw_Extraction/\"+file_pattern)\n",
    "sub_idx=0\n",
    "for path in zscore_file_path:\n",
    "    print(path)\n",
    "    merge_group_z = pd.DataFrame()\n",
    "    #df_move_col = pd.DataFrame()\n",
    "    z_score_ori = pd.read_csv(path)\n",
    "    name_grouped = z_score_ori.groupby('name')\n",
    "    for name, group in name_grouped:\n",
    "        #print(name,group)\n",
    "        # dealing with day data missing issue\n",
    "        \n",
    "        if group.shape[0] == 4:\n",
    "            diffD1D2 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "            diffD1D3 = group.iloc[0,3:]-group.iloc[2,3:]\n",
    "            diffD2D3 = group.iloc[1,3:]-group.iloc[2,3:]\n",
    "            diffD1D4 = group.iloc[0,3:]-group.iloc[3,3:]\n",
    "            diffD2D4 = group.iloc[1,3:]-group.iloc[3,3:]\n",
    "        \n",
    "        # 待修正，可能是123，134，234天的数据，做分类计算\n",
    "        elif group.shape[0] == 3:\n",
    "            \n",
    "            if 1 not in group['day'].tolist(): #D2D3,D2D4\n",
    "                #print(\"D2D3,D2D4:\\n\",group['day'])\n",
    "                diffD2D3 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "                diffD2D4 = group.iloc[0,3:]-group.iloc[2,3:]\n",
    "                diffD1D2 = diffD1D3 = diffD1D4 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "            elif 2 not in group['day'].tolist(): #D1D3 D1D4\n",
    "                #print(\"D1D3 D1D4:\\n\",group['day'])\n",
    "                diffD1D3 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "                diffD1D4 = group.iloc[0,3:]-group.iloc[2,3:]\n",
    "                diffD1D2 = diffD2D3 = diffD2D4 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "            elif 3 not in group['day'].tolist(): #D1D2,D1D4,D2D4\n",
    "                #print(\"D1D2,D1D4,D2D4:\\n\",group['day'])\n",
    "                diffD1D2 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "                diffD1D4 = group.iloc[0,3:]-group.iloc[2,3:]\n",
    "                diffD2D4 = group.iloc[1,3:]-group.iloc[2,3:]\n",
    "                diffD1D3 = diffD2D3 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "            elif 4 not in group['day'].tolist():#D1D2,D1D3,D2D3\n",
    "                #print(\"D1D2,D1D3,D2D3:\\n\",group['day'])\n",
    "                diffD1D2 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "                diffD1D3 = group.iloc[0,3:]-group.iloc[2,3:]\n",
    "                diffD2D3 = group.iloc[1,3:]-group.iloc[2,3:]\n",
    "                diffD2D4 = diffD1D4 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "\n",
    "        # 只有两天的数据，分类计算 12，13，14，23，24，34\n",
    "        elif group.shape[0] == 2: \n",
    "            if 1 and 2 in group['day'].tolist():\n",
    "                #print('day1 and 2:\\n',group['day'])\n",
    "                diffD2D4 = diffD1D4 = diffD2D3 = diffD1D3 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "                diffD1D2 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "            elif 1 and 3 in group['day'].tolist():\n",
    "                #print('day1 and 3:\\n',group['day'])\n",
    "                diffD2D4 = diffD1D4 = diffD2D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "                diffD1D3 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "            elif 1 and 4 in group['day'].tolist():\n",
    "                #print('day1 and 3:\\n',group['day'])\n",
    "                diffD2D4 = diffD1D3 = diffD2D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "                diffD1D4 = group.iloc[0,3:]-group.iloc[1,3:]\n",
    "                \n",
    "            elif 2 and 3 in group['day'].tolist():\n",
    "                #print('day1 and 3:\\n',group['day'])\n",
    "                diffD2D4 = diffD1D4 = diffD1D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "                diffD2D3 = group.iloc[0,3:]-group.iloc[1,3:]            \n",
    "            elif 2 and 4 in group['day'].tolist():\n",
    "                #print('day1 and 3:\\n',group['day'])\n",
    "                diffD1D3 = diffD1D4 = diffD2D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "                diffD2D4 = group.iloc[0,3:]-group.iloc[1,3:]            \n",
    "            else:\n",
    "                diffD2D4 = diffD1D4 = diffD2D3 = diffD1D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "        else:\n",
    "            diffD2D4 = diffD1D4 = diffD2D3 = diffD1D3 = diffD1D2 = group.iloc[0,3:]-group.iloc[0,3:]\n",
    "        \n",
    "        one_group_diffZ = pd.concat([diffD1D2, diffD1D3,diffD1D4, diffD2D3, diffD2D4], axis=0)\n",
    "        one_group_diffZ = pd.DataFrame(one_group_diffZ)\n",
    "        one_group_diffZ = one_group_diffZ.transpose()\n",
    "        one_group_diffZ['name'] = name\n",
    "        one_group_diffZ = one_group_diffZ.set_index('name') \n",
    "        merge_group_z = pd.concat([merge_group_z,one_group_diffZ],axis = 0)\n",
    "    \n",
    "    merge_group_z = merge_group_z.abs()\n",
    "    \n",
    "    # rename columns by adding D1D2 etc.\n",
    "    new_columns = []\n",
    "    for i, col in enumerate(merge_group_z.columns):\n",
    "        if i < 8:\n",
    "            new_columns.append(\"D1D2\" + col)\n",
    "        elif i>=8 and i< 16:\n",
    "            new_columns.append(\"D1D3\" + col)\n",
    "        elif i>=16 and i< 24:\n",
    "            new_columns.append(\"D1D4\" + col)\n",
    "        elif i>=24 and i< 32:\n",
    "            new_columns.append(\"D2D3\" + col)\n",
    "        elif i>=32:\n",
    "            new_columns.append(\"D2D4\" + col)\n",
    "    merge_group_z.columns = new_columns\n",
    "    \n",
    "    \n",
    "    # remove columns to get a new df\n",
    "    df_move_col = pd.DataFrame(index = merge_group_z.index)\n",
    "    for i in range(int(merge_group_z.shape[1]/5)):\n",
    "        k=0\n",
    "        for j in range(int(merge_group_z.shape[1]/8)):\n",
    "        # 0,8,16,24,32\n",
    "            df_move_col = pd.concat([df_move_col,merge_group_z.iloc[:,k+i]],axis = 1)\n",
    "            k+=8\n",
    "    \n",
    "    df_move_col.to_csv(os.getcwd()+'/Raw_Extraction/%s_z_by_day.csv'%sub_folder[sub_idx],index = True)\n",
    "    sub_idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248837de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c93318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   D1A  D1B  D1C  D1D  D1E  D2F  D2G  D2H  D2I  D2J\n",
      "0    1    4    7   10   13   16   19   22   25   28\n",
      "1    2    5    8   11   14   17   20   23   26   29\n",
      "2    3    6    9   12   15   18   21   24   27   30\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f2044b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
